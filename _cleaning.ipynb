{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as math\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the OpenFoodFact dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_products = pd.read_csv('products_clean.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_products.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71758"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean():\n",
    "    # Strips\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].str.strip()\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].str.strip('|')\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].str.strip('`')\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].str.strip('´')\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].str.strip('\"')\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].str.strip('\\'')\n",
    "    # Replace all multiple spaces to ' '\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace =' +', value = ' ', regex = True)\n",
    "    # Replace all multiple '|' to '|'\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='\\|+', value = '|', regex = True)\n",
    "    # Remove space '|' before and after\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='[ ]?\\|[ ]?', value = '|', regex = True)\n",
    "    # Replace all \"' \\w\" to \"'\\w\"\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='(\\'|’)[ ]+', value = '\\'', regex = True)\n",
    "\n",
    "def firstClean():\n",
    "    # Remove all language tag for categories\n",
    "    data_products['categories_tags'] = data_products['categories_tags'].replace(to_replace ='\\w{2}:', value = '', regex = True)\n",
    "    data_products['main_category'] = data_products['main_category'].replace(to_replace ='\\w{2}:', value = '', regex = True)\n",
    "    data_products['countries_en'] = data_products['countries_en'].replace(to_replace ='\\w{2}:', value = '', regex = True)\n",
    "    data_products['categories_en'] = data_products['categories_en'].replace(to_replace ='\\w{2}:', value = '', regex = True)\n",
    "#     # Replace ' ' to '-'\n",
    "#     data_products['countries_en'] = data_products['countries_en'].replace(to_replace =' ', value = '-', regex = True)\n",
    "#     data_products['countries_en'] = data_products['countries_en'].str.lower()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Lower case column\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].str.lower()\n",
    "    # Replace special character\n",
    "    data_products['ingredients_text'] =  data_products['ingredients_text'].replace(to_replace ='œ', value = 'oe', regex = True)\n",
    "    data_products['ingredients_text'] =  data_products['ingredients_text'].replace(to_replace ='ﬁ', value = 'fi', regex = True)\n",
    "    data_products['ingredients_text'] =  data_products['ingredients_text'].replace(to_replace =' +', value = ' ', regex = True)\n",
    "    \n",
    "    clean()\n",
    "    \n",
    "    # Remove all unuseful character (™,!,#,=,^,$,@,❤,®,±,°,¹,²,³,¼,½,¾,º)\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='(™|!|#|=|\\+|\\-|\\^|\\$|@|❤|®|±|°|¹|²|³|¼|½|¾|º)', value = '', regex = True)\n",
    "    # Remove common unuseful text 'ingredients :'\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='(ingredients|ingredient|ingrédients|ingrédient)[ ]?[:]?[ ]?', value = '', regex = True)\n",
    "    # Remove all language tag\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='\\w{2}:', value = '', regex = True)\n",
    "    \n",
    "    # Replace all (_, ') to ' '\n",
    "    data_products['ingredients_text'] =  data_products['ingredients_text'].replace(to_replace ='(_| \\')', value = ' ', regex = True)\n",
    "    # Remove all '<balise>' and '</balise>'\n",
    "    data_products['ingredients_text'] =  data_products['ingredients_text'].replace(to_replace ='<(\\/)?(\\w){1,20}>', value = '', regex = True)\n",
    "    # Remove all '(+33°)' and '+23°'\n",
    "    data_products['ingredients_text'] =  data_products['ingredients_text'].replace(to_replace ='(\\(|（)?[ ]?(\\+|\\-)?[ ]?\\d{1,5}(?:\\.\\d+)?[ ]?°[ ]?(\\)|）)?', value = '', regex = True)\n",
    "    # Remove all quantities '40g'\n",
    "    data_products['ingredients_text'] =  data_products['ingredients_text'].replace(to_replace ='\\d+(\\.\\d+)?[ ]?(mg|g|kg|ml|cl|l|kj|oz|µg|pg|ug)', value = '', regex = True)\n",
    "    # Remove all ref \n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='\\w?\\d{1,4}\\w?', value = '', regex = True)\n",
    "    # Remove all '(33%)', '{33%}' and '33%'\n",
    "    data_products['ingredients_text'] =  data_products['ingredients_text'].replace(to_replace ='(\\(|\\{)?[ ]?\\d{1,3}(?:\\.\\d+)?[ ]?(\\%|％)[ ]?(\\)|\\})?', value = '', regex = True)\n",
    "\n",
    "     # Replace seperation characters to '|' (and, , ,:,*,;,[,],{,},&,•,%,％,‰,.,·,/,<,>,-,—,‘,’,“,⁸,€,℅,⅓,⅕,●,♦,、,。,一,﻿,（,）,(,),，,~,«,»,¡,¤,§)\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='( and |\\,|\\:|\\*|;|\\[|\\]|\\{|\\}|\\&|•|%|％|‰|\\.|·|\\/|<|>|—|‘|’|“|⁸|€|℅|⅓|⅕|●|♦|、|。|一|﻿|（|）|\\(|\\)|，|~|«|»|¡|¤|§)', value = '|', regex = True)\n",
    "    \n",
    "    clean()\n",
    "    \n",
    "def lastClean():\n",
    "    # Remove all ingredients too small\n",
    "    for x in range(5):\n",
    "        data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='^.{1,2}$', value = '', regex = True)\n",
    "        data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='^.{1,2}\\|', value = '', regex = True)\n",
    "        data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='\\|.{1,2}$', value = '', regex = True)\n",
    "        data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='\\|.{1,2}\\|', value = '|', regex = True)\n",
    "    \n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='^\\'', value = '', regex = True)\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='\\|\\'', value = '|', regex = True)\n",
    "    \n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='^\\´', value = '', regex = True)\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='\\|\\´', value = '|', regex = True)\n",
    "    \n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='^ +', value = '', regex = True)\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace =' +$', value = '', regex = True)\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace =' +\\|', value = '|', regex = True)\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='\\| +', value = '|', regex = True)\n",
    "\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='^ $', value = '', regex = True)\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='^ \\|', value = '', regex = True)\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='\\| $', value = '', regex = True)\n",
    "    data_products['ingredients_text'] = data_products['ingredients_text'].replace(to_replace ='\\| \\|', value = '|', regex = True)\n",
    "    \n",
    "    clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstClean()\n",
    "lastClean()\n",
    "data_products = data_products.where(data_products.notnull(), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 400\n",
    "iStop = i + 100\n",
    "while i < iStop:\n",
    "    print(\"---\")\n",
    "    print(i)\n",
    "    print(\"---\")\n",
    "    print(data_products['ingredients_text'][i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the data to new CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compression_opts = dict(method='zip', archive_name='products.csv')\n",
    "# # data_products.to_csv('out_products.zip', index=False, compression=compression_opts, encoding='utf-8-sig')\n",
    "# data_products.to_csv('products.csv', index=False, encoding='utf-8-sig')\n",
    "# data_products.head(100).to_csv('products_small.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create categories dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCategoriesTags = []\n",
    "allCategoriesEn = [] \n",
    "for index, row in data_products.iterrows():\n",
    "    categories_tags = row['categories_tags'].split(\"|\")\n",
    "    categories_en = row['categories_en'].split(\"|\")\n",
    "    for index, category_tag in enumerate(categories_tags):\n",
    "        allCategoriesTags.append(category_tag)\n",
    "        allCategoriesEn.append(categories_en[index])\n",
    "\n",
    "len(allCategoriesTags)\n",
    "len(allCategoriesEn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_categories = pd.DataFrame(\n",
    "    {'tag': allCategoriesTags,\n",
    "     'label': allCategoriesEn\n",
    "    })\n",
    "data_categories = data_categories.drop_duplicates(['tag'])\n",
    "data_categories.sort_values(by=['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_categories.to_csv('categories.csv', index=True, index_label=\"index\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ingredients dataset (before formatting ingredients for products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allIngredients = [] \n",
    "for index, text in enumerate(data_products['ingredients_text']):\n",
    "    ingredients = text.split(\"|\")\n",
    "    for ingredient in ingredients:\n",
    "        if(ingredient != '') : allIngredients.append(ingredient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(allIngredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISTINCT\n",
    "allIngredients = list(set(allIngredients))\n",
    "print(len(allIngredients))\n",
    "# ABC SORT\n",
    "allIngredients = sorted(allIngredients, key=str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingredients = pd.DataFrame(data=allIngredients, columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingredients['label'] = allIngredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "iStop = iStop\n",
    "while i < iStop:\n",
    "    print(\"---\")\n",
    "    print(i)\n",
    "    print(\"---\")\n",
    "    print(data_ingredients.iloc[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingredients = data_ingredients.reset_index(drop=True)\n",
    "data_ingredients['id'] = data_ingredients['id'].replace(to_replace =' ', value = '_', regex = True)\n",
    "data_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingredients.to_csv('ingredients.csv', index=True, index_label=\"index\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create countries dataset (before formatting countries for products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCountries = [] \n",
    "for index, text in enumerate(data_products['countries_en']):\n",
    "    if text is not None:\n",
    "        countries = text.split(\"|\")\n",
    "        for country in countries:\n",
    "            if(country != '') : allCountries.append(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(allCountries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISTINCT\n",
    "allCountries = list(set(allCountries))\n",
    "print(len(allCountries))\n",
    "# ABC SORT\n",
    "allCountries = sorted(allCountries, key=str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_countries = pd.DataFrame(data=allCountries, columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_countries['label'] = allCountries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "iStop = i + 100\n",
    "while i < iStop:\n",
    "    print(\"---\")\n",
    "    print(i)\n",
    "    print(\"---\")\n",
    "    print(data_countries.iloc[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_countries = data_countries.reset_index(drop=True)\n",
    "data_countries['id'] = data_countries['id'].str.lower().replace(to_replace =' ', value = '_', regex = True)\n",
    "data_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_countries.to_csv('countries.csv', index=True, index_label=\"index\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create products dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_products['countries_en'] = data_products['countries_en'].str.lower().replace(to_replace =' ', value = '_', regex = True)\n",
    "data_products['ingredients_text'] = data_products['ingredients_text'].str.lower().replace(to_replace =' ', value = '_', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_products['countries_en'] = data_products['countries_en'].astype(str)\n",
    "data_products['allergens'] = data_products['allergens'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Product:\n",
    "    def __init__(self, code, url, product_name, categories, categories_tags, categories_en, countries_en, ingredients_text, allergens, nutriscore_score, nutriscore_grade, nova_group, pnns_groups_1, pnns_groups_2, main_category, main_category_en, energy_kj_100g, energy_kcal_100g, energy_100g, fat_100g, saturated_fat_100g, trans_fat_100g, cholesterol_100g, carbohydrates_100g, sugars_100g, fiber_100g, proteins_100g, salt_100g, sodium_100g, nutrition_score_fr_100g):\n",
    "        self.code = code\n",
    "#         self.url = url\n",
    "        self.product_name = product_name\n",
    "#         self.categories = categories\n",
    "        self.main_category = main_category\n",
    "        \n",
    "        self.categories = categories_tags.split(\"|\")\n",
    "#         self.categories_tags = categories_tags\n",
    "#         self.categories_en = categories_en\n",
    "        self.countries = countries_en.split(\"|\")\n",
    "#         self.countries_en = countries_en\n",
    "        self.ingredients = ingredients_text.split(\"|\")\n",
    "#         self.ingredients_text = ingredients_text\n",
    "#         self.allergens = allergens.split(\"|\")\n",
    "#         self.allergens = allergens\n",
    "        if nutriscore_score is not None: self.nutriscore_score = nutriscore_score\n",
    "        if nutriscore_grade is not None: self.nutriscore_grade = nutriscore_grade\n",
    "        if nova_group is not None: self.nova_group = nova_group\n",
    "#         if pnns_groups_1 is not None: self.pnns_groups_1 = pnns_groups_1\n",
    "#         if pnns_groups_2 is not None: self.pnns_groups_2 = pnns_groups_2\n",
    "#         if main_category_en is not None: self.main_category_en = main_category_en\n",
    "#         if energy_kj_100g is not None: self.energy_kj_100g = energy_kj_100g\n",
    "#         if energy_kcal_100g is not None: self.energy_kcal_100g = energy_kcal_100g\n",
    "#         if energy_100g is not None: self.energy_100g = energy_100g\n",
    "        if fat_100g is not None: self.fat_100g = fat_100g\n",
    "        if saturated_fat_100g is not None: self.saturated_fat_100g = saturated_fat_100g\n",
    "        if trans_fat_100g is not None: self.trans_fat_100g = trans_fat_100g\n",
    "        if cholesterol_100g is not None: self.cholesterol_100g = cholesterol_100g\n",
    "        if carbohydrates_100g is not None: self.carbohydrates_100g = carbohydrates_100g\n",
    "        if sugars_100g is not None: self.sugars_100g = sugars_100g\n",
    "        if fiber_100g is not None: self.fiber_100g = fiber_100g\n",
    "        if proteins_100g is not None: self.proteins_100g = proteins_100g\n",
    "        if salt_100g is not None: self.salt_100g = salt_100g\n",
    "        if sodium_100g is not None: self.sodium_100g = sodium_100g\n",
    "#         if nutrition_score_fr_100g is not None: self.nutrition_score_fr_100g = nutrition_score_fr_100g\n",
    "        \n",
    "        \n",
    "class OpenFoodFact():\n",
    "    def __init__(self, products: List[Product]):\n",
    "        self.products = products\n",
    "        \n",
    "products = [(Product(row['code'], row['url'], row['product_name'], row['categories'], row['categories_tags'], row['categories_en'], row['countries_en'], row['ingredients_text'], row['allergens'], row['nutriscore_score'], row['nutriscore_grade'], row['nova_group'], row['pnns_groups_1'], row['pnns_groups_2'], row['main_category'], row['main_category_en'], row['energy-kj_100g'], row['energy-kcal_100g'], row['energy_100g'], row['fat_100g'], row['saturated-fat_100g'], row['trans-fat_100g'], row['cholesterol_100g'], row['carbohydrates_100g'], row['sugars_100g'], row['fiber_100g'], row['proteins_100g'], row['salt_100g'], row['sodium_100g'], row['nutrition-score-fr_100g'])) for index, row in data_products.iterrows()]\n",
    "\n",
    "openfoodfact = OpenFoodFact(products=products)\n",
    "# products[1].ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.dumps(openfoodfact, default=lambda o: o.__dict__, indent=4, ensure_ascii=False)\n",
    "text_file = open(\"products.json\", \"w\", encoding='utf-8')\n",
    "text_file.write(json_data)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# products[len(products)-1].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
